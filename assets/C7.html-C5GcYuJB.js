import{_ as t}from"./plugin-vue_export-helper-DlAUqK2U.js";import{o as n,c as r,a as e,b as a}from"./app-CLljTwst.js";const o={},i=e("h1",{id:"chapter-7-temporal-difference-learning",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#chapter-7-temporal-difference-learning"},[e("span",null,"Chapter 7 Temporal-Difference learning")])],-1),l=e("p",null,"TD learning refers a wide range of algorithms.",-1),s=e("p",null,[a("TD algorithm can solve Bellman equation of a given policy "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mi",null,"π")]),e("annotation",{encoding:"application/x-tex"},"\\pi")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.4306em"}}),e("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"π")])])]),a(" without model.")],-1),m=[i,l,s];function p(c,h){return n(),r("div",null,m)}const f=t(o,[["render",p],["__file","C7.html.vue"]]),u=JSON.parse(`{"path":"/ML/C7.html","title":"Chapter 7 Temporal-Difference learning","lang":"zh-CN","frontmatter":{"icon":"qianghuaxuexi","ReadingTime":true,"date":"2025-11-05T00:00:00.000Z","Word":true,"PageView":true,"category":"RL","description":"Chapter 7 Temporal-Difference learning TD learning refers a wide range of algorithms. TD algorithm can solve Bellman equation of a given policy π without model.","head":[["meta",{"property":"og:url","content":"https://ryanlee-ljx.github.io/ML/C7.html"}],["meta",{"property":"og:site_name","content":"RyanLee's blog"}],["meta",{"property":"og:title","content":"Chapter 7 Temporal-Difference learning"}],["meta",{"property":"og:description","content":"Chapter 7 Temporal-Difference learning TD learning refers a wide range of algorithms. TD algorithm can solve Bellman equation of a given policy π without model."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-11-05T12:10:07.000Z"}],["meta",{"property":"article:author","content":"RyanLee_ljx"}],["meta",{"property":"article:published_time","content":"2025-11-05T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-11-05T12:10:07.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Chapter 7 Temporal-Difference learning\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-11-05T00:00:00.000Z\\",\\"dateModified\\":\\"2025-11-05T12:10:07.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"RyanLee_ljx\\",\\"email\\":\\"2284771024@qq.com\\"}]}"]]},"headers":[],"git":{"createdTime":1762332835000,"updatedTime":1762344607000,"contributors":[{"name":"Flame","email":"2284771024@qq.com","commits":2}]},"readingTime":{"minutes":0.13,"words":40},"filePathRelative":"ML/C7.md","localizedDate":"2025年11月5日","excerpt":"\\n<p>TD learning refers a wide range of algorithms.</p>\\n<p>TD algorithm can solve Bellman equation of a given policy <span v-pre=\\"\\" class=\\"katex\\"><span class=\\"katex-mathml\\"><math xmlns=\\"http://www.w3.org/1998/Math/MathML\\"><semantics><mrow><mi>π</mi></mrow><annotation encoding=\\"application/x-tex\\">\\\\pi</annotation></semantics></math></span><span class=\\"katex-html\\" aria-hidden=\\"true\\"><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.4306em;\\"></span><span class=\\"mord mathnormal\\" style=\\"margin-right:0.03588em;\\">π</span></span></span></span> without model.</p>","autoDesc":true}`);export{f as comp,u as data};
